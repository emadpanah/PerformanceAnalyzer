import cv2  # Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙˆÛŒØ¯Ø¦Ùˆ Ùˆ ØªØµØ§ÙˆÛŒØ±
import mediapipe as mp  # Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø­Ø§Ù„Øª Ø¨Ø¯Ù†
import numpy as np  # Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø¹Ø¯Ø¯ÛŒ
import pandas as pd  # Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
import streamlit as st  # Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯
import plotly.express as px  # Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§
import argparse  # Ø¨Ø±Ø§ÛŒ Ø¢Ø±Ú¯ÙˆÙ…Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ø®Ø· ÙØ±Ù…Ø§Ù†
import os  # Ø¨Ø±Ø§ÛŒ Ù…Ø¯ÛŒØ±ÛŒØª ÙØ§ÛŒÙ„
import time  # Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ ÙØ±ÛŒÙ…â€ŒÙ‡Ø§ÛŒ Ø¯ÛŒØ¨Ø§Ú¯

# ØªÙ†Ø¸ÛŒÙ… MediaPipe Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø­Ø§Ù„Øª Ø¨Ø¯Ù†
mp_pose = mp.solutions.pose
pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.2)
mp_drawing = mp.solutions.drawing_utils

# ØªØ§Ø¨Ø¹ Ø§ØµÙ„Ø§Ø­ Ú†Ø±Ø®Ø´ ÙˆÛŒØ¯Ø¦Ùˆ
def rotate_frame(frame, rotation_code=cv2.ROTATE_90_COUNTERCLOCKWISE):
    return cv2.rotate(frame, rotation_code)

# ØªØ§Ø¨Ø¹ ØªØ´Ø®ÛŒØµ Ø­Ø§Ù„Øª Ø¯Ø± Ù‡Ø± ÙØ±ÛŒÙ…
def detect_state(frame, prev_landmarks):
    state = "Away/Moving"
    movement_detected = False
    
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = pose.process(rgb_frame)
    
    if results.pose_landmarks:
        mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
        cv2.imshow('Debug Frame', frame)
        cv2.waitKey(1)
    
    if results.pose_landmarks:
        landmarks = results.pose_landmarks.landmark
        if landmarks[mp_pose.PoseLandmark.LEFT_HIP].visibility > 0.3 and \
           landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].visibility > 0.3:
            if prev_landmarks:
                dist = np.linalg.norm(np.array([landmarks[mp_pose.PoseLandmark.NOSE].x,
                                               landmarks[mp_pose.PoseLandmark.NOSE].y]) -
                                     np.array([prev_landmarks[mp_pose.PoseLandmark.NOSE].x,
                                               prev_landmarks[mp_pose.PoseLandmark.NOSE].y]))
                if dist > 0.05:
                    movement_detected = True
            
            state = "Productive" if movement_detected else "Idle"
        
        return state, results.pose_landmarks.landmark, frame  # ØªØºÛŒÛŒØ± Ø¨Ù‡ .landmark
    return state, None, frame

# ØªØ§Ø¨Ø¹ ØªØ­Ù„ÛŒÙ„ ÙˆÛŒØ¯Ø¦Ùˆ
def analyze_video(video_path):
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise ValueError("Ø®Ø·Ø§: Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù† ÙØ§ÛŒÙ„ ÙˆÛŒØ¯Ø¦Ùˆ Ø±Ø§ Ø¨Ø§Ø² Ú©Ø±Ø¯")
    
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    duration = total_frames / fps
    
    states = []
    prev_landmarks = None
    frame_count = 0
    debug_frames = []
    
    output_dir = "output"
    frames_dir = os.path.join(output_dir, "frames")
    os.makedirs(frames_dir, exist_ok=True)
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        frame = rotate_frame(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)  # Ø§ØµÙ„Ø§Ø­ Ú†Ø±Ø®Ø´
        frame_count += 1
        if frame_count % 3 != 0:
            continue
        state, prev_landmarks, debug_frame = detect_state(frame, prev_landmarks)
        states.append(state)
        
        if frame_count % 10 == 0:
            cv2.imwrite(os.path.join(frames_dir, f"frame_{frame_count}.jpg"), debug_frame)
            debug_frames.append(debug_frame)
    
    cap.release()
    cv2.destroyAllWindows()
    
    state_counts = pd.Series(states).value_counts(normalize=True) * 100
    productive_pct = state_counts.get("Productive", 0)
    unproductive_pct = 100 - productive_pct
    
    report = {
        "Ù…Ø¯Øª Ø²Ù…Ø§Ù† Ú©Ù„ (Ø«Ø§Ù†ÛŒÙ‡)": duration,
        "Ø±Ø²ÙˆÙ„ÙˆØ´Ù†": f"{width}x{height}",
        "ÙØ±ÛŒÙ… Ø¯Ø± Ø«Ø§Ù†ÛŒÙ‡": fps,
        "ØªØ¹Ø¯Ø§Ø¯ ÙØ±ÛŒÙ…â€ŒÙ‡Ø§": total_frames,
        "Ø¯Ø±ØµØ¯ Ù…ÙˆÙ„Ø¯": productive_pct,
        "Ø¯Ø±ØµØ¯ ØºÛŒØ±Ù…ÙˆÙ„Ø¯": unproductive_pct,
        "ØªÙÚ©ÛŒÚ© Ø­Ø§Ù„Ø§Øª": state_counts.to_dict()
    }
    
    pd.DataFrame([report]).to_csv(os.path.join(output_dir, "analysis_report_v1.csv"), index=False)
    return report, state_counts, debug_frames

# ØªØ§Ø¨Ø¹ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯
def show_dashboard(report=None, state_counts=None, debug_frames=None):
    st.title("ğŸ“Š Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ø¹Ù…Ù„Ú©Ø±Ø¯ (ØªÚ©â€ŒÙ†ÙØ±Ù‡)")
    
    if report is None:
        st.header("Ø¢Ù¾Ù„ÙˆØ¯ ÙˆÛŒØ¯Ø¦Ùˆ")
        video_file = st.file_uploader("ÙˆÛŒØ¯Ø¦Ùˆ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ (MP4)", type=["mp4"])
        if video_file:
            video_path = os.path.join("videos", "uploaded_video.mp4")
            os.makedirs("videos", exist_ok=True)
            with open(video_path, "wb") as f:
                f.write(video_file.getbuffer())
            st.success("ÙˆÛŒØ¯Ø¦Ùˆ Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯. ØªØ­Ù„ÛŒÙ„ Ø¯Ø± Ø­Ø§Ù„ Ø§Ù†Ø¬Ø§Ù…...")
            report, state_counts, debug_frames = analyze_video(video_path)
    
    if report:
        st.header("Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙˆÛŒØ¯Ø¦Ùˆ")
        st.write(f"Ù…Ø¯Øª Ø²Ù…Ø§Ù†: {report['Ù…Ø¯Øª Ø²Ù…Ø§Ù† Ú©Ù„ (Ø«Ø§Ù†ÛŒÙ‡)']} Ø«Ø§Ù†ÛŒÙ‡")
        st.write(f"Ø±Ø²ÙˆÙ„ÙˆØ´Ù†: {report['Ø±Ø²ÙˆÙ„ÙˆØ´Ù†']}")
        st.write(f"ÙØ±ÛŒÙ… Ø¯Ø± Ø«Ø§Ù†ÛŒÙ‡: {report['ÙØ±ÛŒÙ… Ø¯Ø± Ø«Ø§Ù†ÛŒÙ‡']}")
        st.write(f"ØªØ¹Ø¯Ø§Ø¯ ÙØ±ÛŒÙ…â€ŒÙ‡Ø§: {report['ØªØ¹Ø¯Ø§Ø¯ ÙØ±ÛŒÙ…â€ŒÙ‡Ø§']}")
        
        st.header("Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„")
        fig = px.pie(values=[report["Ø¯Ø±ØµØ¯ Ù…ÙˆÙ„Ø¯"], report["Ø¯Ø±ØµØ¯ ØºÛŒØ±Ù…ÙˆÙ„Ø¯"]],
                     names=["Ù…ÙˆÙ„Ø¯", "ØºÛŒØ±Ù…ÙˆÙ„Ø¯"],
                     title="ØªÙÚ©ÛŒÚ© Ø¨Ù‡Ø±Ù‡â€ŒÙˆØ±ÛŒ",
                     color_discrete_sequence=["#00CC96", "#EF553B"])
        st.plotly_chart(fig)
        
        fig_states = px.bar(x=state_counts.index, y=state_counts.values,
                            labels={"x": "Ø­Ø§Ù„Øª", "y": "Ø¯Ø±ØµØ¯ (%)"},
                            title="ØªÙˆØ²ÛŒØ¹ Ø­Ø§Ù„Ø§Øª",
                            color=state_counts.index,
                            color_discrete_map={"Productive": "#00CC96", "Idle": "#EF553B", "Away/Moving": "#636EFA"})
        st.plotly_chart(fig_states)
        
        st.header("Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„")
        st.table(pd.DataFrame([report]))
        
        st.header("ÙØ±ÛŒÙ… Ù†Ù…ÙˆÙ†Ù‡ (Ø¯ÛŒØ¨Ø§Ú¯)")
        if debug_frames:
            frame = debug_frames[0]
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            st.image(frame_rgb, caption="ÙØ±ÛŒÙ… Ù†Ù…ÙˆÙ†Ù‡ Ø¨Ø§ Ù†Ù‚Ø§Ø· Ú©Ù„ÛŒØ¯ÛŒ", use_column_width=True)
        
        st.header("Ø°Ø®ÛŒØ±Ù‡ Ú¯Ø²Ø§Ø±Ø´")
        if st.button("Ø°Ø®ÛŒØ±Ù‡ Ú¯Ø²Ø§Ø±Ø´ Ø¨Ù‡ JSON"):
            pd.DataFrame([report]).to_json(os.path.join("output", "analysis_report_v1.json"), orient="records", lines=True, force_ascii=False)
            st.success("Ú¯Ø²Ø§Ø±Ø´ Ø¨Ù‡ JSON Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ø¹Ù…Ù„Ú©Ø±Ø¯ (ØªÚ©â€ŒÙ†ÙØ±Ù‡)")
    parser.add_argument("--video", type=str, help="Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ ÙˆÛŒØ¯Ø¦Ùˆ")
    parser.add_argument("--dashboard", action="store_true", help="Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ù¾Ø³ Ø§Ø² ØªØ­Ù„ÛŒÙ„")
    args = parser.parse_args()
    
    if args.video:
        report, state_counts, debug_frames = analyze_video(args.video)
        print("ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ù…Ù„ Ø´Ø¯. Ú¯Ø²Ø§Ø±Ø´ Ø¯Ø± output/analysis_report_v1.csv Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
        print(report)
        if args.dashboard:
            show_dashboard(report, state_counts, debug_frames)
    else:
        show_dashboard()